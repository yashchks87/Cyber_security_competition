{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data files\n",
    "spamData= pd.read_csv('./FinalDataset/Spam.csv')\n",
    "# len(spamData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values by column wise\n",
    "a = spamData.isnull().sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning with replacing null values with mean-by-column\n",
    "spamData['avgpathtokenlen'] = spamData['avgpathtokenlen'].fillna(spamData['avgpathtokenlen'].mean())\n",
    "spamData['NumberRate_Extension'] = spamData['NumberRate_Extension'].fillna(spamData['NumberRate_Extension'].mean())\n",
    "spamData['NumberRate_AfterPath'] = spamData['NumberRate_AfterPath'].fillna(spamData['NumberRate_AfterPath'].mean())\n",
    "spamData['Entropy_DirectoryName'] = spamData['Entropy_DirectoryName'].fillna(spamData['Entropy_DirectoryName'].mean())\n",
    "spamData['Entropy_Filename'] = spamData['Entropy_Filename'].fillna(spamData['Entropy_Filename'].mean())\n",
    "spamData['Entropy_Extension'] = spamData['Entropy_Extension'].fillna(spamData['Entropy_Extension'].mean())\n",
    "spamData['Entropy_Afterpath'] = spamData['Entropy_Afterpath'].fillna(spamData['Entropy_Afterpath'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divison of data by columns\n",
    "# x1 is for independent columns, whilee y1 is target column which is type of attack.\n",
    "x = spamData.iloc[:,0:40]\n",
    "y = spamData.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashchoksi/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature selection \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model=ExtraTreesClassifier()\n",
    "model.fit(x,y)\n",
    "# Extract best 10 features from all 79 features\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "feature_imp= pd.Series(model.feature_importances_,index=x.columns)\n",
    "feature_imp.nlargest(10).plot(kind='barh')\n",
    "plt.xlabel(\"Probability of Predictive Factors\", fontsize=25)\n",
    "plt.ylabel(\"Predictive Factors\", fontsize= 25)\n",
    "# plt.title(\"Feature selection for spam\", fontsize=30)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As everytime features are changing on every run \n",
    "# Stroring feeatures in ts variable.\n",
    "ts = (feature_imp.nlargest(10).to_dict())\n",
    "ts = ts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashchoksi/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Final columns for training and testing for model\n",
    "columns_to_keep = x[ts]\n",
    "from sklearn.model_selection import train_test_split\n",
    "# TODO: What is random state and how it's value is chosen?\n",
    "features_train,features_test,y_train,y_test = train_test_split(columns_to_keep,y,test_size=0.3,random_state=66)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Intiate the model\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(features_train,y_train)\n",
    "score = rfc.score(features_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988489871086557"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = rfc.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply actual data and predcited data.\n",
    "def confusion(actual, predicted):\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix(actual, predicted))\n",
    "    print(\"Precision Score: \", precision_score(actual, predicted, pos_label='spam'))\n",
    "    print(\"Recall score: \", recall_score(actual, predicted, pos_label='spam'))\n",
    "    print(\"Accuracy of our prediction: \", accuracy_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[2392    2]\n",
      " [   3 1947]]\n",
      "Precision Score:  0.9989738327347357\n",
      "Recall score:  0.9984615384615385\n",
      "Accuracy of our prediction:  0.9988489871086557\n"
     ]
    }
   ],
   "source": [
    "confusion(y_test, predicted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['SymbolCount_Domain', 'tld', 'NumberofDotsinURL', 'NumberRate_AfterPath', 'domainlength', 'Entropy_Afterpath', 'SymbolCount_URL', 'ArgUrlRatio', 'CharacterContinuityRate']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
